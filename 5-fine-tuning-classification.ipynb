{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib version: 3.10.3\n",
      "numpy version: 2.2.6\n",
      "tiktoken version: 0.9.0\n",
      "torch version: 2.7.0\n",
      "pandas version: 2.3.1\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\"matplotlib\",  # Plotting library\n",
    "        \"numpy\",       # PyTorch & TensorFlow dependency\n",
    "        \"tiktoken\",    # Tokenizer\n",
    "        \"torch\",       # Deep learning library\n",
    "        \"pandas\"       # Dataset loading\n",
    "       ]\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sms_spam_collection/SMSSpamCollection.tsv already exists. Skipping download and extraction.\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
    "zip_path = \"sms_spam_collection.zip\"\n",
    "extracted_path = \"sms_spam_collection\"\n",
    "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
    "\n",
    "def download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path):\n",
    "    if data_file_path.exists():\n",
    "        print(f\"{data_file_path} already exists. Skipping download and extraction.\")\n",
    "        return\n",
    "\n",
    "    # Downloading the file\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        with open(zip_path, \"wb\") as out_file:\n",
    "            out_file.write(response.read())\n",
    "\n",
    "    # Unzipping the file\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(extracted_path)\n",
    "\n",
    "    # Add .tsv file extension\n",
    "    original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
    "    os.rename(original_file_path, data_file_path)\n",
    "    print(f\"File downloaded and saved as {data_file_path}\")\n",
    "\n",
    "try:\n",
    "    download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)\n",
    "except (urllib.error.HTTPError, urllib.error.URLError, TimeoutError) as e:\n",
    "    print(f\"Primary URL failed: {e}. Trying backup URL...\")\n",
    "    url = \"https://f001.backblazeb2.com/file/LLMs-from-scratch/sms%2Bspam%2Bcollection.zip\"\n",
    "    download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                               Text\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham               Will ü b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(data_file_path, sep=\"\\t\", header=None, names=[\"Label\", \"Text\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     4825\n",
      "spam     747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     747\n",
      "spam    747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Balance each class to the same number of instances.\n",
    "def create_balanced_dataset(df):\n",
    "    \n",
    "    # Count the instances of \"spam\"\n",
    "    num_spam = df[df[\"Label\"] == \"spam\"].shape[0]\n",
    "    \n",
    "    # Randomly sample \"ham\" instances to match the number of \"spam\" instances\n",
    "    ham_subset = df[df[\"Label\"] == \"ham\"].sample(num_spam, random_state=123)\n",
    "    \n",
    "    # Combine ham \"subset\" with \"spam\"\n",
    "    balanced_df = pd.concat([ham_subset, df[df[\"Label\"] == \"spam\"]])\n",
    "\n",
    "    return balanced_df\n",
    "\n",
    "\n",
    "balanced_df = create_balanced_dataset(df)\n",
    "print(balanced_df[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4307</th>\n",
       "      <td>0</td>\n",
       "      <td>Awww dat is sweet! We can think of something t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4138</th>\n",
       "      <td>0</td>\n",
       "      <td>Just got to  &amp;lt;#&amp;gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4831</th>\n",
       "      <td>0</td>\n",
       "      <td>The word \"Checkmate\" in chess comes from the P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4461</th>\n",
       "      <td>0</td>\n",
       "      <td>This is wishing you a great day. Moji told me ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5440</th>\n",
       "      <td>0</td>\n",
       "      <td>Thank you. do you generally date the brothas?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5537</th>\n",
       "      <td>1</td>\n",
       "      <td>Want explicit SEX in 30 secs? Ring 02073162414...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5540</th>\n",
       "      <td>1</td>\n",
       "      <td>ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5547</th>\n",
       "      <td>1</td>\n",
       "      <td>Had your contract mobile 11 Mnths? Latest Moto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5566</th>\n",
       "      <td>1</td>\n",
       "      <td>REMINDER FROM O2: To get 2.50 pounds free call...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>1</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1494 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Label                                               Text\n",
       "4307      0  Awww dat is sweet! We can think of something t...\n",
       "4138      0                             Just got to  &lt;#&gt;\n",
       "4831      0  The word \"Checkmate\" in chess comes from the P...\n",
       "4461      0  This is wishing you a great day. Moji told me ...\n",
       "5440      0      Thank you. do you generally date the brothas?\n",
       "...     ...                                                ...\n",
       "5537      1  Want explicit SEX in 30 secs? Ring 02073162414...\n",
       "5540      1  ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...\n",
       "5547      1  Had your contract mobile 11 Mnths? Latest Moto...\n",
       "5566      1  REMINDER FROM O2: To get 2.50 pounds free call...\n",
       "5567      1  This is the 2nd time we have tried 2 contact u...\n",
       "\n",
       "[1494 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\": 0, \"spam\": 1})\n",
    "balanced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function that randomly divides the dataset into training, validation, and test subsets\n",
    "def random_split(df, train_frac, validation_frac):\n",
    "    # Shuffle the entire DataFrame\n",
    "    df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
    "\n",
    "    # Calculate split indices\n",
    "    train_end = int(len(df) * train_frac)\n",
    "    validation_end = train_end + int(len(df) * validation_frac)\n",
    "\n",
    "    # Split the DataFrame\n",
    "    train_df = df[:train_end]\n",
    "    validation_df = df[train_end:validation_end]\n",
    "    test_df = df[validation_end:]\n",
    "\n",
    "    return train_df, validation_df, test_df\n",
    "\n",
    "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)\n",
    "# Test size is implied to be 0.2 as the remainder\n",
    "\n",
    "train_df.to_csv(\"train.csv\", index=None)\n",
    "validation_df.to_csv(\"validation.csv\", index=None)\n",
    "test_df.to_csv(\"test.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad all messages to the length of the longest message in the dataset or batch.\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class SpamDataset(Dataset):\n",
    "    def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id=50256):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "\n",
    "        # Pre-tokenize texts\n",
    "        self.encoded_texts = [\n",
    "            tokenizer.encode(text) for text in self.data[\"Text\"]\n",
    "        ]\n",
    "\n",
    "        if max_length is None:\n",
    "            self.max_length = self._longest_encoded_length()\n",
    "        else:\n",
    "            self.max_length = max_length\n",
    "            # Truncate sequences if they are longer than max_length\n",
    "            self.encoded_texts = [\n",
    "                encoded_text[:self.max_length]\n",
    "                for encoded_text in self.encoded_texts\n",
    "            ]\n",
    "\n",
    "        # Pad sequences to the longest sequence\n",
    "        self.encoded_texts = [\n",
    "            encoded_text + [pad_token_id] * (self.max_length - len(encoded_text))\n",
    "            for encoded_text in self.encoded_texts\n",
    "        ]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        encoded = self.encoded_texts[index]\n",
    "        label = self.data.iloc[index][\"Label\"]\n",
    "        return (\n",
    "            torch.tensor(encoded, dtype=torch.long),\n",
    "            torch.tensor(label, dtype=torch.long)\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def _longest_encoded_length(self):\n",
    "        max_length = 0\n",
    "        for encoded_text in self.encoded_texts:\n",
    "            encoded_length = len(encoded_text)\n",
    "            if encoded_length > max_length:\n",
    "                max_length = encoded_length\n",
    "        return max_length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SpamDataset(\n",
    "    csv_file=\"train.csv\",\n",
    "    max_length=None,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "print(train_dataset.max_length)\n",
    "\n",
    "val_dataset = SpamDataset(\n",
    "    csv_file=\"validation.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "test_dataset = SpamDataset(\n",
    "    csv_file=\"test.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "Input batch dimensions: torch.Size([8, 120])\n",
      "Label batch dimensions torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for input_batch, target_batch in train_loader:\n",
    "    pass\n",
    "\n",
    "print(\"Input batch dimensions:\", input_batch.shape)\n",
    "print(\"Label batch dimensions\", target_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 training batches\n",
      "19 validation batches\n",
      "38 test batches\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(train_loader)} training batches\")\n",
    "print(f\"{len(val_loader)} validation batches\")\n",
    "print(f\"{len(test_loader)} test batches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize a model with pretrained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "INPUT_PROMPT = \"Every effort moves\"\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"drop_rate\": 0.0,        # Dropout rate\n",
    "    \"qkv_bias\": True         # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "assert train_dataset.max_length <= BASE_CONFIG[\"context_length\"], (\n",
    "    f\"Dataset length {train_dataset.max_length} exceeds model's context \"\n",
    "    f\"length {BASE_CONFIG['context_length']}. Reinitialize data sets with \"\n",
    "    f\"`max_length={BASE_CONFIG['context_length']}`\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load weights\n",
    "import torch\n",
    "from previous_chapters import GPTModel, generate_text_simple\n",
    "\n",
    "file_name = \"gpt2-small-124M.pth\"\n",
    "gpt = GPTModel(BASE_CONFIG)\n",
    "gpt.load_state_dict(torch.load(file_name, weights_only=True))\n",
    "gpt.eval()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "gpt.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves forward, but it's not enough.\n",
      "\n",
      "\"I'm not going to sit here and say, 'I'm not going to do this,'\n"
     ]
    }
   ],
   "source": [
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "model=gpt.to(device)\n",
    "\n",
    "# Generate text\n",
    "import tiktoken\n",
    "torch.manual_seed(123)\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves\", tokenizer).to(device),\n",
    "    max_new_tokens=30,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the following text 'spam'? Answer with 'yes' or 'no': 'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.'\n",
      "\n",
      "The following text 'spam'? Answer with 'yes' or 'no': 'You are a winner\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    "    \"Is the following text 'spam'? Answer with 'yes' or 'no':\"\n",
    "    \" 'You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.'\"\n",
    ")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_2, tokenizer),\n",
    "    max_new_tokens=23,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add a classification head\n",
    "Replace the original output layer to a smaller output layer that maps to 2 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTModel(\n",
      "  (tok_emb): Embedding(50257, 768)\n",
      "  (pos_emb): Embedding(1024, 768)\n",
      "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
      "  (trf_blocks): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (3): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (4): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (5): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (6): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (7): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (8): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (9): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (10): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (11): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (final_norm): LayerNorm()\n",
      "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Look at the architecture of the model, the output layer dimension is 50257.\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the model first.\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the output layer.\n",
    "torch.manual_seed(123)\n",
    "\n",
    "num_classes = 2\n",
    "model.out_head = torch.nn.Linear(in_features=BASE_CONFIG[\"emb_dim\"], out_features=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the output layer, the final layernorm, the last transformer block trainable.\n",
    "for param in model.trf_blocks[-1].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in model.final_norm.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: tensor([[5211,  345,  423,  640]])\n",
      "Inputs dimensions: torch.Size([1, 4])\n",
      "Outputs:\n",
      " tensor([[[-1.5854,  0.9904],\n",
      "         [-3.7235,  7.4548],\n",
      "         [-2.2661,  6.6049],\n",
      "         [-3.5983,  3.9902]]])\n",
      "Outputs dimensions: torch.Size([1, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "# Feed inputs to the model as normal\n",
    "inputs = tokenizer.encode(\"Do you have time\")\n",
    "inputs = torch.tensor(inputs).unsqueeze(0)\n",
    "print(\"Inputs:\", inputs)\n",
    "print(\"Inputs dimensions:\", inputs.shape) # shape: (batch_size, num_tokens)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(inputs)\n",
    "\n",
    "print(\"Outputs:\\n\", outputs)\n",
    "print(\"Outputs dimensions:\", outputs.shape) # shape: (batch_size, num_tokens, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the classification loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output token: tensor([[-3.5983,  3.9902]])\n",
      "Class label: 1\n"
     ]
    }
   ],
   "source": [
    "# Convert the last output row to a 2 dimension probability distribution.\n",
    "print(\"Last output token:\", outputs[:, -1, :])\n",
    "logits = outputs[:, -1, :]\n",
    "label = torch.argmax(logits)\n",
    "print(\"Class label:\", label.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy_loader(data_loader, model, device, num_batches=None):\n",
    "    model.eval()\n",
    "    correct_predictions, num_examples = 0, 0\n",
    "\n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                logits = model(input_batch)[:, -1, :]  # Logits of last output token\n",
    "            predicted_labels = torch.argmax(logits, dim=-1)\n",
    "\n",
    "            num_examples += predicted_labels.shape[0]\n",
    "            correct_predictions += (predicted_labels == target_batch).sum().item()\n",
    "        else:\n",
    "            break\n",
    "    return correct_predictions / num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on mps device.\n",
      "Training accuracy: 46.25%\n",
      "Validation accuracy: 45.00%\n",
      "Test accuracy: 48.75%\n"
     ]
    }
   ],
   "source": [
    "# Results before fine-tuning\n",
    "\n",
    "# Note:\n",
    "# Uncommenting the following lines will allow the code to run on Apple Silicon chips, if applicable,\n",
    "# which is approximately 2x faster than on an Apple CPU (as measured on an M3 MacBook Air).\n",
    "# As of this writing, in PyTorch 2.4, the results obtained via CPU and MPS were identical.\n",
    "# However, in earlier versions of PyTorch, you may observe different results when using MPS.\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "   device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "   device = torch.device(\"mps\")\n",
    "else:\n",
    "   device = torch.device(\"cpu\")\n",
    "print(f\"Running on {device} device.\")\n",
    "\n",
    "model.to(device) # no assignment model = model.to(device) necessary for nn.Module classes\n",
    "\n",
    "torch.manual_seed(123) # For reproducibility due to the shuffling in the training data loader\n",
    "\n",
    "train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use cross entropy loss as loss function\n",
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)[:, -1, :]  # Logits of last output token\n",
    "    loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.453\n",
      "Validation loss: 2.583\n",
      "Test loss: 2.322\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): # Disable gradient tracking for efficiency because we are not training, yet\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "    test_loss = calc_loss_loader(test_loader, model, device, num_batches=5)\n",
    "\n",
    "print(f\"Training loss: {train_loss:.3f}\")\n",
    "print(f\"Validation loss: {val_loss:.3f}\")\n",
    "print(f\"Test loss: {test_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tune the model on supervised data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                            eval_freq, eval_iter):\n",
    "    # Initialize lists to track losses and examples seen\n",
    "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "    examples_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward() # Calculate loss gradients\n",
    "            optimizer.step() # Update model weights using loss gradients\n",
    "            examples_seen += input_batch.shape[0] # New: track examples instead of tokens\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        # Calculate accuracy after each epoch\n",
    "        train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "        print(f\"Training accuracy: {train_accuracy*100:.2f}% | \", end=\"\")\n",
    "        print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "        train_accs.append(train_accuracy)\n",
    "        val_accs.append(val_accuracy)\n",
    "\n",
    "    return train_losses, val_losses, train_accs, val_accs, examples_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 2.153, Val loss 2.392\n",
      "Ep 1 (Step 000050): Train loss 0.617, Val loss 0.637\n",
      "Ep 1 (Step 000100): Train loss 0.523, Val loss 0.557\n",
      "Training accuracy: 70.00% | Validation accuracy: 72.50%\n",
      "Ep 2 (Step 000150): Train loss 0.561, Val loss 0.489\n",
      "Ep 2 (Step 000200): Train loss 0.419, Val loss 0.397\n",
      "Ep 2 (Step 000250): Train loss 0.409, Val loss 0.353\n",
      "Training accuracy: 82.50% | Validation accuracy: 85.00%\n",
      "Ep 3 (Step 000300): Train loss 0.333, Val loss 0.320\n",
      "Ep 3 (Step 000350): Train loss 0.340, Val loss 0.306\n",
      "Training accuracy: 90.00% | Validation accuracy: 90.00%\n",
      "Ep 4 (Step 000400): Train loss 0.136, Val loss 0.200\n",
      "Ep 4 (Step 000450): Train loss 0.153, Val loss 0.132\n",
      "Ep 4 (Step 000500): Train loss 0.222, Val loss 0.137\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Ep 5 (Step 000550): Train loss 0.207, Val loss 0.143\n",
      "Ep 5 (Step 000600): Train loss 0.083, Val loss 0.074\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Training completed in 1.46 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 5\n",
    "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=50, eval_iter=5,\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_values(epochs_seen, examples_seen, train_values, val_values, label=\"loss\"):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_values, label=f\"Training {label}\")\n",
    "    ax1.plot(epochs_seen, val_values, linestyle=\"-.\", label=f\"Validation {label}\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(label.capitalize())\n",
    "    ax1.legend()\n",
    "\n",
    "    # Create a second x-axis for examples seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(examples_seen, train_values, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Examples seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(f\"{label}-plot.pdf\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
