{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy version: 2.2.6\n",
      "matplotlib version: 3.10.3\n",
      "tiktoken version: 0.9.0\n",
      "torch version: 2.7.0\n",
      "tqdm version: 4.67.1\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\n",
    "    \"numpy\",       # PyTorch & TensorFlow dependency\n",
    "    \"matplotlib\",  # Plotting library\n",
    "    \"tiktoken\",    # Tokenizer\n",
    "    \"torch\",       # Deep learning library\n",
    "    \"tqdm\",        # Progress bar\n",
    "]\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 1100\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import urllib\n",
    "\n",
    "\n",
    "def download_and_load_file(file_path, url):\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            text_data = response.read().decode(\"utf-8\")\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(text_data)\n",
    "\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "file_path = \"instruction-data.json\"\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch\"\n",
    "    \"/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
    ")\n",
    "\n",
    "data = download_and_load_file(file_path, url)\n",
    "print(\"Number of entries:\", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example entry:\n",
      " {'instruction': 'Identify the correct spelling of the following word.', 'input': 'Ocassion', 'output': \"The correct spelling is 'Occasion.'\"}\n"
     ]
    }
   ],
   "source": [
    "print(\"Example entry:\\n\", data[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "\n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "\n",
    "    return instruction_text + input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Identify the correct spelling of the following word.\n",
      "\n",
      "### Input:\n",
      "Ocassion\n",
      "\n",
      "### Response:\n",
      "The correct spelling is 'Occasion.'\n"
     ]
    }
   ],
   "source": [
    "# Alpaca prompt style\n",
    "model_input = format_input(data[50])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[50]['output']}\"\n",
    "\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is an antonym of 'complicated'?\n",
      "\n",
      "### Response:\n",
      "An antonym of 'complicated' is 'simple'.\n"
     ]
    }
   ],
   "source": [
    "# Alpaca prompt style \n",
    "model_input = format_input(data[999])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[999]['output']}\"\n",
    "\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set length: 935\n",
      "Validation set length: 55\n",
      "Test set length: 110\n"
     ]
    }
   ],
   "source": [
    "# Divide the dataset\n",
    "train_portion = int(len(data) * 0.85)  # 85% for training\n",
    "test_portion = int(len(data) * 0.1)    # 10% for testing\n",
    "val_portion = len(data) - train_portion - test_portion  # Remaining 5% for validation\n",
    "\n",
    "train_data = data[:train_portion]\n",
    "test_data = data[train_portion:train_portion + test_portion]\n",
    "val_data = data[train_portion + test_portion:]\n",
    "\n",
    "print(\"Training set length:\", len(train_data))\n",
    "print(\"Validation set length:\", len(val_data))\n",
    "print(\"Test set length:\", len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Organize data into training batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class InstructionDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "\n",
    "        # Pre-tokenize texts\n",
    "        self.encoded_texts = []\n",
    "        for entry in data:\n",
    "            instruction_plus_input = format_input(entry)\n",
    "            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
    "            full_text = instruction_plus_input + response_text\n",
    "            self.encoded_texts.append(\n",
    "                tokenizer.encode(full_text)\n",
    "            )\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.encoded_texts[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This custom collate function pads the training examples in each batch to have the same length (but different batches can have different lengths).\n",
    "def custom_collate_draft_1(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    # Find the longest sequence in the batch\n",
    "    # and increase the max length by +1, which will add one extra\n",
    "    # padding token below\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "\n",
    "    # Pad and prepare inputs\n",
    "    inputs_lst = []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        # Add an <|endoftext|> token\n",
    "        new_item += [pad_token_id]\n",
    "        # Pad sequences to batch_max_length\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] *\n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        # Via padded[:-1], we remove the extra padded token\n",
    "        # that has been added via the +1 setting in batch_max_length\n",
    "        # (the extra padding token will be relevant in later codes)\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        inputs_lst.append(inputs)\n",
    "\n",
    "    # Convert list of inputs to tensor and transfer to target device\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    return inputs_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "inputs_1 = [0, 1, 2, 3, 4]\n",
    "inputs_2 = [5, 6]\n",
    "inputs_3 = [7, 8, 9]\n",
    "\n",
    "batch = (\n",
    "    inputs_1,\n",
    "    inputs_2,\n",
    "    inputs_3\n",
    ")\n",
    "\n",
    "print(custom_collate_draft_1(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_draft_2(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    # Find the longest sequence in the batch\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "\n",
    "    # Pad and prepare inputs\n",
    "    inputs_lst, targets_lst = [], []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        # Add an <|endoftext|> token\n",
    "        new_item += [pad_token_id]\n",
    "        # Pad sequences to max_length\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] *\n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1])  # Truncate the last token for inputs\n",
    "        targets = torch.tensor(padded[1:])  # Shift +1 to the right for targets\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "\n",
    "    # Convert list of inputs to tensor and transfer to target device\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256, 50256, 50256, 50256],\n",
      "        [    8,     9, 50256, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "inputs, targets = custom_collate_draft_2(batch)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_fn(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    ignore_index=-100,\n",
    "    allowed_max_length=None,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    # Find the longest sequence in the batch\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "\n",
    "    # Pad and prepare inputs and targets\n",
    "    inputs_lst, targets_lst = [], []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        # Add an <|endoftext|> token\n",
    "        new_item += [pad_token_id]\n",
    "        # Pad sequences to max_length\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] *\n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1])  # Truncate the last token for inputs\n",
    "        targets = torch.tensor(padded[1:])  # Shift +1 to the right for targets\n",
    "\n",
    "        # New: Replace all but the first padding tokens in targets by ignore_index\n",
    "        mask = targets == pad_token_id\n",
    "        indices = torch.nonzero(mask).squeeze()\n",
    "        if indices.numel() > 1:\n",
    "            targets[indices[1:]] = ignore_index\n",
    "\n",
    "        # New: Optionally truncate to maximum sequence length\n",
    "        if allowed_max_length is not None:\n",
    "            inputs = inputs[:allowed_max_length]\n",
    "            targets = targets[:allowed_max_length]\n",
    "\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "\n",
    "    # Convert list of inputs and targets to tensors and transfer to target device\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256,  -100,  -100,  -100],\n",
      "        [    8,     9, 50256,  -100,  -100]])\n"
     ]
    }
   ],
   "source": [
    "inputs, targets = custom_collate_fn(batch)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create data loaders for an instruction dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Note:\n",
    "# Uncommenting the following lines will allow the code to run on Apple Silicon chips, if applicable,\n",
    "# which is much faster than on an Apple CPU (as measured on an M3 MacBook Air).\n",
    "# However, the resulting loss values may be slightly different.\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "   device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "   device = torch.device(\"mps\")\n",
    "else:\n",
    "   device = torch.device(\"cpu\")\n",
    "\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "customized_collate_fn = partial(\n",
    "    custom_collate_fn,\n",
    "    device=device,\n",
    "    allowed_max_length=1024\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_dataset = InstructionDataset(train_data, tokenizer)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = InstructionDataset(val_data, tokenizer)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "test_dataset = InstructionDataset(test_data, tokenizer)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 89]) torch.Size([8, 89])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 88]) torch.Size([8, 88])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 87]) torch.Size([8, 87])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 57]) torch.Size([8, 57])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 82]) torch.Size([8, 82])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 78]) torch.Size([8, 78])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for inputs, targets in train_loader:\n",
    "    print(inputs.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 30003,  6525,   262,  6827,  1262,   257,\n",
      "          985,   576,    13,   198,   198, 21017, 23412,    25,   198,   464,\n",
      "         5156,   318,   845, 13779,    13,   198,   198, 21017, 18261,    25,\n",
      "          198,   464,  5156,   318,   355, 13779,   355,   257,  4936,    13,\n",
      "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
      "       device='mps:0')\n",
      "tensor([  318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,   257,\n",
      "         2882,   326, 20431, 32543,   262,  2581,    13,   198,   198, 21017,\n",
      "        46486,    25,   198, 30003,  6525,   262,  6827,  1262,   257,   985,\n",
      "          576,    13,   198,   198, 21017, 23412,    25,   198,   464,  5156,\n",
      "          318,   845, 13779,    13,   198,   198, 21017, 18261,    25,   198,\n",
      "          464,  5156,   318,   355, 13779,   355,   257,  4936,    13, 50256,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100],\n",
      "       device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "print(inputs[0])\n",
    "print(targets[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load a pre-trained LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from previous_chapters import GPTModel, load_weights_into_gpt\n",
    "# If the `previous_chapters.py` file is not available locally,\n",
    "# you can import it from the `llms-from-scratch` PyPI package.\n",
    "# For details, see: https://github.com/rasbt/LLMs-from-scratch/tree/main/pkg\n",
    "# E.g.,\n",
    "# from llms_from_scratch.ch04 import GPTModel\n",
    "# from llms_from_scratch.ch05 import download_and_load_gpt2, load_weights_into_gpt\n",
    "\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"drop_rate\": 0.0,        # Dropout rate\n",
    "    \"qkv_bias\": True         # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load weights\n",
    "import torch\n",
    "from previous_chapters import GPTModel, generate_text_simple\n",
    "\n",
    "file_name = \"gpt2-small-124M.pth\"\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "model.load_state_dict(torch.load(file_name, weights_only=True))\n",
    "model.eval()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "input_text = format_input(val_data[0])\n",
    "print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from previous_chapters import (\n",
    "    generate,\n",
    "    text_to_token_ids,\n",
    "    token_ids_to_text\n",
    ")\n",
    "\n",
    "\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(input_text, tokenizer),\n",
    "    max_new_tokens=35,\n",
    "    context_size=BASE_CONFIG[\"context_length\"],\n",
    "    eos_id=50256,\n",
    ")\n",
    "generated_text = token_ids_to_text(token_ids, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Instruction:\n",
      "\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n",
      "\n",
      "### Instruction:\n",
      "\n",
      "Convert the active\n"
     ]
    }
   ],
   "source": [
    "response_text = (\n",
    "    generated_text[len(input_text):]\n",
    "    .replace(\"### Response:\", \"\")\n",
    "    .strip()\n",
    ")\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning the LLM on instruction data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from previous_chapters import (\n",
    "    calc_loss_loader,\n",
    "    train_model_simple\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 4.167110824584961\n",
      "Validation loss: 4.0509062767028805\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 3.119, Val loss 3.069\n",
      "Ep 1 (Step 000005): Train loss 1.697, Val loss 1.570\n",
      "Ep 1 (Step 000010): Train loss 1.096, Val loss 1.164\n",
      "Ep 1 (Step 000015): Train loss 1.053, Val loss 1.083\n",
      "Ep 1 (Step 000020): Train loss 0.970, Val loss 1.038\n",
      "Ep 1 (Step 000025): Train loss 0.920, Val loss 1.002\n",
      "Ep 1 (Step 000030): Train loss 0.960, Val loss 0.978\n",
      "Ep 1 (Step 000035): Train loss 0.877, Val loss 0.951\n",
      "Ep 1 (Step 000040): Train loss 0.847, Val loss 0.943\n",
      "Ep 1 (Step 000045): Train loss 0.777, Val loss 0.925\n",
      "Ep 1 (Step 000050): Train loss 0.869, Val loss 0.911\n",
      "Ep 1 (Step 000055): Train loss 0.923, Val loss 0.893\n",
      "Ep 1 (Step 000060): Train loss 0.872, Val loss 0.878\n",
      "Ep 1 (Step 000065): Train loss 0.800, Val loss 0.867\n",
      "Ep 1 (Step 000070): Train loss 0.694, Val loss 0.860\n",
      "Ep 1 (Step 000075): Train loss 0.706, Val loss 0.855\n",
      "Ep 1 (Step 000080): Train loss 0.753, Val loss 0.847\n",
      "Ep 1 (Step 000085): Train loss 0.680, Val loss 0.836\n",
      "Ep 1 (Step 000090): Train loss 0.729, Val loss 0.827\n",
      "Ep 1 (Step 000095): Train loss 0.652, Val loss 0.821\n",
      "Ep 1 (Step 000100): Train loss 0.634, Val loss 0.808\n",
      "Ep 1 (Step 000105): Train loss 0.728, Val loss 0.803\n",
      "Ep 1 (Step 000110): Train loss 0.718, Val loss 0.799\n",
      "Ep 1 (Step 000115): Train loss 0.672, Val loss 0.796\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The chef cooks the meal every day.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Input: The following is a sentence.  ### Response\n",
      "Ep 2 (Step 000120): Train loss 0.591, Val loss 0.790\n",
      "Ep 2 (Step 000125): Train loss 0.625, Val loss 0.801\n",
      "Ep 2 (Step 000130): Train loss 0.583, Val loss 0.789\n",
      "Ep 2 (Step 000135): Train loss 0.546, Val loss 0.791\n",
      "Ep 2 (Step 000140): Train loss 0.579, Val loss 0.789\n",
      "Ep 2 (Step 000145): Train loss 0.518, Val loss 0.785\n",
      "Ep 2 (Step 000150): Train loss 0.520, Val loss 0.781\n",
      "Ep 2 (Step 000155): Train loss 0.594, Val loss 0.785\n",
      "Ep 2 (Step 000160): Train loss 0.585, Val loss 0.785\n",
      "Ep 2 (Step 000165): Train loss 0.537, Val loss 0.782\n",
      "Ep 2 (Step 000170): Train loss 0.440, Val loss 0.775\n",
      "Ep 2 (Step 000175): Train loss 0.479, Val loss 0.769\n",
      "Ep 2 (Step 000180): Train loss 0.540, Val loss 0.760\n",
      "Ep 2 (Step 000185): Train loss 0.567, Val loss 0.757\n",
      "Ep 2 (Step 000190): Train loss 0.442, Val loss 0.742\n",
      "Ep 2 (Step 000195): Train loss 0.469, Val loss 0.729\n",
      "Ep 2 (Step 000200): Train loss 0.408, Val loss 0.728\n",
      "Ep 2 (Step 000205): Train loss 0.480, Val loss 0.724\n",
      "Ep 2 (Step 000210): Train loss 0.516, Val loss 0.725\n",
      "Ep 2 (Step 000215): Train loss 0.539, Val loss 0.734\n",
      "Ep 2 (Step 000220): Train loss 0.414, Val loss 0.738\n",
      "Ep 2 (Step 000225): Train loss 0.487, Val loss 0.738\n",
      "Ep 2 (Step 000230): Train loss 0.425, Val loss 0.742\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The chef cooks the meal every day.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Input: What is the chemical symbol for carbon?  \n",
      "Training completed in 5.05 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00005, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 2\n",
    "\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=format_input(val_data[0]), tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from previous_chapters import plot_losses\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract and save responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Rewrite the sentence using a simile.\n",
      "\n",
      "### Input:\n",
      "The car is very fast.\n",
      "\n",
      "Correct response:\n",
      ">> The car is as fast as lightning.\n",
      "\n",
      "Model response:\n",
      ">> The car is as fast as a horse.\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What type of cloud is typically associated with thunderstorms?\n",
      "\n",
      "Correct response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "Model response:\n",
      ">> The type of cloud typically associated with thunderstorms is a tropical rainforest.\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Name the author of 'Pride and Prejudice'.\n",
      "\n",
      "Correct response:\n",
      ">> Jane Austen.\n",
      "\n",
      "Model response:\n",
      ">> The author of 'Pride and Prejudice' is Robert Frost.\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "\n",
    "for entry in test_data[:3]:\n",
    "\n",
    "    input_text = format_input(entry)\n",
    "\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    response_text = (\n",
    "        generated_text[len(input_text):]\n",
    "        .replace(\"### Response:\", \"\")\n",
    "        .strip()\n",
    ")\n",
    "\n",
    "    print(input_text)\n",
    "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
    "    print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
    "    print(\"-------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 84/110 [01:21<00:27,  1.07s/it]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for i, entry in tqdm(enumerate(test_data), total=len(test_data)):\n",
    "\n",
    "    input_text = format_input(entry)\n",
    "\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    response_text = generated_text[len(input_text):].replace(\"### Response:\", \"\").strip()\n",
    "\n",
    "    test_data[i][\"model_response\"] = response_text\n",
    "\n",
    "\n",
    "with open(\"instruction-data-with-response.json\", \"w\") as file:\n",
    "    json.dump(test_data, file, indent=4)  # \"indent\" for pretty-printing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
